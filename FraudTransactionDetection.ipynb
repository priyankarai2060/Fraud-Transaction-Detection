{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a763f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e4d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:/unified_metor_content/fraud_detection/fraud_detection/\" \n",
    "\n",
    "file_list = sorted(glob.glob(data_path + \"*.pkl\"))\n",
    "\n",
    "# Read and concatenate all daily files\n",
    "df_all = pd.concat([pd.read_pickle(file) for file in file_list], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7fd6fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c902919",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['datetime'] = pd.to_datetime(df_all['TX_DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a402ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all['TX_HOUR'] = df_all['TX_DATETIME'].dt.hour\n",
    "#df_all['TX_DAY'] = df_all['TX_DATETIME'].dt.day\n",
    "#df_all['TX_DAYOFWEEK'] = df_all['TX_DATETIME'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "#df_all['TX_IS_WEEKEND'] = df_all['TX_DAYOFWEEK'].isin([5, 6]).astype(int)\n",
    "#df_all['TX_IS_NIGHT'] = df_all['TX_HOUR'].between(0, 6).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a659eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_counts= df_all[df_all['TX_FRAUD'] == 1].groupby('TERMINAL_ID').size()\n",
    "df_all['fraud_count'] = df_all['TERMINAL_ID'].map(fraud_counts).fillna(0).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9725c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"fraud_amt\"] = (df_all[\"TX_AMOUNT\"] > 220).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6929905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRANSACTION_ID</th>\n",
       "      <th>TX_DATETIME</th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>TERMINAL_ID</th>\n",
       "      <th>TX_AMOUNT</th>\n",
       "      <th>TX_TIME_SECONDS</th>\n",
       "      <th>TX_TIME_DAYS</th>\n",
       "      <th>TX_FRAUD</th>\n",
       "      <th>TX_FRAUD_SCENARIO</th>\n",
       "      <th>datetime</th>\n",
       "      <th>fraud_count</th>\n",
       "      <th>fraud_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-01 00:00:31</td>\n",
       "      <td>596</td>\n",
       "      <td>3156</td>\n",
       "      <td>57.16</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-01 00:00:31</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-01 00:02:10</td>\n",
       "      <td>4961</td>\n",
       "      <td>3412</td>\n",
       "      <td>81.51</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-01 00:02:10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-01 00:07:56</td>\n",
       "      <td>2</td>\n",
       "      <td>1365</td>\n",
       "      <td>146.00</td>\n",
       "      <td>476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-01 00:07:56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-04-01 00:09:29</td>\n",
       "      <td>4128</td>\n",
       "      <td>8737</td>\n",
       "      <td>64.49</td>\n",
       "      <td>569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-01 00:09:29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-01 00:10:34</td>\n",
       "      <td>927</td>\n",
       "      <td>9906</td>\n",
       "      <td>50.99</td>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-01 00:10:34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRANSACTION_ID         TX_DATETIME CUSTOMER_ID TERMINAL_ID  TX_AMOUNT  \\\n",
       "0               0 2018-04-01 00:00:31         596        3156      57.16   \n",
       "1               1 2018-04-01 00:02:10        4961        3412      81.51   \n",
       "2               2 2018-04-01 00:07:56           2        1365     146.00   \n",
       "3               3 2018-04-01 00:09:29        4128        8737      64.49   \n",
       "4               4 2018-04-01 00:10:34         927        9906      50.99   \n",
       "\n",
       "  TX_TIME_SECONDS TX_TIME_DAYS  TX_FRAUD  TX_FRAUD_SCENARIO  \\\n",
       "0              31            0         0                  0   \n",
       "1             130            0         0                  0   \n",
       "2             476            0         0                  0   \n",
       "3             569            0         0                  0   \n",
       "4             634            0         0                  0   \n",
       "\n",
       "             datetime  fraud_count  fraud_amt  \n",
       "0 2018-04-01 00:00:31           17          0  \n",
       "1 2018-04-01 00:02:10            1          0  \n",
       "2 2018-04-01 00:07:56            1          0  \n",
       "3 2018-04-01 00:09:29            0          0  \n",
       "4 2018-04-01 00:10:34            0          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5da59d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "638e287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca33d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.utils import resample\n",
    "\n",
    "#df_majority = df_all[df_all.TX_FRAUD == 0]\n",
    "#df_minority = df_all[df_all.TX_FRAUD == 1]\n",
    "\n",
    "#df_majority_downsampled = resample(df_majority,\n",
    "                                   #replace=False,\n",
    "                                   #n_samples=len(df_minority)*5,\n",
    "                                   #random_state=42)\n",
    "\n",
    "#df_balanced = pd.concat([df_majority_downsampled, df_minority])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24532357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "df_all = df_all.sort_values('TX_DATETIME')\n",
    "\n",
    "# Add a date-only column\n",
    "#df_all['date'] = df_all['datetime'].dt.date\n",
    "df_all['date'] = df_all['datetime'].dt.floor('d')\n",
    "\n",
    "# Get all unique transaction dates\n",
    "unique_dates = df_all['date'].unique()\n",
    "\n",
    "# Simulate fraud for each day except the last 14 (so we have a full 14-day window)\n",
    "for day in unique_dates[:-14]:\n",
    "    #current_day = pd.to_datetime(day)\n",
    "    current_day = day  # Already a Timestamp\n",
    "    window_end = current_day + timedelta(days=14)\n",
    "\n",
    "    # Get customers active on this day\n",
    "    active_customers = df_all[df_all['date'] == day]['CUSTOMER_ID'].unique()\n",
    "\n",
    "    if len(active_customers) < 3:\n",
    "        continue  # skip if fewer than 3 customers\n",
    "\n",
    "    # Select 3 customers at random\n",
    "    selected_customers = np.random.choice(active_customers, size=3, replace=False)\n",
    "\n",
    "    for cust_id in selected_customers:\n",
    "        # Filter transactions in the next 14 days\n",
    "        mask = (\n",
    "            (df_all['CUSTOMER_ID'] == cust_id) &\n",
    "            (df_all['datetime'] > current_day) &\n",
    "            (df_all['datetime'] <= window_end)\n",
    "        )\n",
    "        cust_txns = df_all[mask]\n",
    "\n",
    "        if len(cust_txns) == 0:\n",
    "            continue\n",
    "\n",
    "        # Pick 1/3 of them (or at least 1) to make fraudulent\n",
    "        num_fraud = max(1, len(cust_txns) // 3)\n",
    "        fraud_indices = cust_txns.sample(n=num_fraud, random_state=42).index\n",
    "\n",
    "        # Apply fraud changes\n",
    "        #df_all.loc[fraud_indices, 'TX_AMOUNT'] *= 5\n",
    "        # Safely apply multiplier only to numeric rows\n",
    "        df_all.loc[fraud_indices, 'TX_AMOUNT'] = df_all.loc[fraud_indices, 'TX_AMOUNT'].astype(float) * 5\n",
    "\n",
    "        df_all.loc[fraud_indices, 'TX_FRAUD'] = 1\n",
    "        df_all.loc[fraud_indices, 'TX_FRAUD_SCENARIO'] = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b3fa049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by time\n",
    "#df = df_balanced.sort_values('TX_DATETIME')\n",
    "df = df_all.drop(columns = ['TX_DATETIME','datetime','TX_FRAUD_SCENARIO'])\n",
    "df['TX_TIME_SECONDS'] = pd.to_numeric(df['TX_TIME_SECONDS'], errors='coerce')\n",
    "df['TX_TIME_DAYS'] = pd.to_numeric(df['TX_TIME_DAYS'], errors='coerce')\n",
    "df['CUSTOMER_ID'] = pd.to_numeric(df['CUSTOMER_ID'], errors='coerce')\n",
    "df['TERMINAL_ID'] = pd.to_numeric(df['TERMINAL_ID'], errors='coerce')\n",
    "# Define your split point (e.g., 70% of the data for training)\n",
    "split_index = int(0.7 * len(df))\n",
    "\n",
    "X = df.drop(columns = ['TX_FRAUD'])\n",
    "y = df['TX_FRAUD']\n",
    "\n",
    "X_train, X_test = X.iloc[:split_index],X.iloc[split_index:]\n",
    "y_train, y_test = y.iloc[:split_index],y.iloc[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f03924ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['TX_AMOUNT', 'TX_TIME_SECONDS', 'TX_TIME_DAYS']\n",
    "preprocessor = ColumnTransformer(transformers = [('num',StandardScaler(),numeric_features)],\n",
    "                                remainder = 'passthrough',\n",
    "                                force_int_remainder_cols=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce6cd3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps=[\n",
    "    #('preprocessor', preprocessor),\n",
    "    #('classifier', RandomForestClassifier())\n",
    "#]\n",
    "pipeline1 = Pipeline([('preprocessor',preprocessor),('clf',LogisticRegression(max_iter=1000))])\n",
    "\n",
    "#pipeline2 = Pipeline([('xg',XGBClassifier(scale_pos_weight=110,  # Use ratio of non-fraud/fraud\n",
    "    \n",
    "    #eval_metric='logloss'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d2ae9b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pipeline1\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:662\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    657\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    658\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    659\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    660\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    661\u001b[0m         )\n\u001b[1;32m--> 662\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1222\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1220\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1222\u001b[0m X, y \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m   1223\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1224\u001b[0m     X,\n\u001b[0;32m   1225\u001b[0m     y,\n\u001b[0;32m   1226\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[0;32m   1228\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1229\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1230\u001b[0m )\n\u001b[0;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1371\u001b[0m     X,\n\u001b[0;32m   1372\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1373\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1374\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1375\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1376\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1377\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[0;32m   1378\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39mensure_all_finite,\n\u001b[0;32m   1379\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1380\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1381\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1382\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1383\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1384\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1385\u001b[0m )\n\u001b[0;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:839\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    837\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 839\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'Timestamp'"
     ]
    }
   ],
   "source": [
    "pipeline1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "def log_to_text(model_name, y_test, y_pred, y_proba, filename='results_log.txt'):\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(f\"\\nModel: {model_name}\\n\")\n",
    "        f.write(f\"Accuracy: {acc}\\n\")\n",
    "        f.write(f\"Precision: {prec}\\n\")\n",
    "        f.write(f\"Recall: {rec}\\n\")\n",
    "        f.write(f\"F1 Score: {f1}\\n\")\n",
    "        f.write(f\"ROC AUC: {auc}\\n\")\n",
    "        f.write(f\"Confusion Matrix:\\n{cm}\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec9bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline1.predict(X_test)\n",
    "y_proba = pipeline1.predict_proba(X_test)[:, 1] \n",
    "log_to_text('logistic regression after converting fraud simulants',y_test,y_pred,y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e2cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparision = pd.DataFrame({\n",
    "    'y_test' : y_test.values,\n",
    "    'y_pred' : y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d597c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5779b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Classification report (prints everything)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# If you want AUC, use predicted probabilities\n",
    "y_proba = pipeline1.predict_proba(X_test)[:, 1]  # Prob of class 1\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Print everything\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", auc)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd5e40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
